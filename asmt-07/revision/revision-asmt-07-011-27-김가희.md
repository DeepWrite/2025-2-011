---
title: (개선) 과제-07 개인별 논증 구조 작성하기 011-27 김가희
layout: home
nav_order: 99
parent: 011-27 김가희 (과제-07)
permalink: /asmt-07/011-27/revision
---

# (개선) 과제-07 개인별 논증 구조 작성하기 011-27 김가희 

## 개선 사항 메모

1. 핵심 용어(연루)를 정의한다. 
2. 전제들이 단순 나열처럼 보이지 않게 수정하고 재배열한다. 
3. 전제를 직접 공격하는 반론을 제시해 정교화한다. 
4. 하나의 논문에만 의존하지 않고, 참고 문헌을 추가한다. 
5. 전제와 더 직접적인 연관이 있는 반론 제기한다.

## 제목: 왜 플랫폼은 콘텐츠를 적극적으로 중재해야 하는가?  

## 1. 쟁점과 딜레마

| 구분 | 내용 |
|:---|:---|
| 주제(Topic) | 소셜 미디어 플랫폼의 콘텐츠 중재 행위에 대한 도덕적 책임과 그 철학적 근거 |
| 도전하려는 쟁점 | "발행인인가 단순 플랫폼인가"라는 기존의 이분법적 쟁점을 비판하며, 플랫폼이 사용자의 **부당한 발언**을 중재해야 할 **도덕적 의무**의 근거와 범위를 묻는다.  |
| 딜레마/난제 | 중재에 소극적이면 해악에 **연루**되고, 적극 개입하면 **사적 검열** 비판을 받는다. |
| 딜레마/난제 해소/해결 방법 | **연루**라는 도덕적 실패가 **사적 검열** 비판보다 더 심각하며, **사적 검열** 반론 자체가 국가와 플랫폼의 의무를 혼동한 오류임을 논증하여 적극적 중재를 정당화한다.  |

① 주제(Topic): 소셜 미디어 플랫폼의 콘텐츠 중재 행위에 대한 도덕적 책임과 그 철학적 근거 

② 도전하는 학술적 쟁점: "발행인인가 단순 플랫폼인가"라는 기존의 이분법적 쟁점을 비판하며, 플랫폼이 사용자의 **부당한 발언**을 중재해야 할 **도덕적 의무**가 있는가, 있다면 그 근거와 범위는 무엇인가?

- **플랫폼 자체만으로 최소한의 의무가 있는가?**  
- **플랫폼은 왜 신고가 들어오기도 전에 적극적으로 감시해야 하는가?**  
- **플랫폼의 알고리즘 자체에 도덕적 책임이 있는가?**

③ 유발되는 딜레마 또는 난제

- 딜레마 구조
  - **(A)** 플랫폼이 중재에 소극적이거나 중립을 지키면, 부당한 발언(혐오, 폭력 선동 등)이 만연하는 것을 방치하게 된다. 이는 타인의 해악에 **연루(Complicity)**되는 심각한 도덕적 실패를 초래한다. 
  - **(B)** 그러나 플랫폼이 적극적으로 개입하면, **부당한 사적 검열**이라는 비판과 **표현의 자유**를 침해한다는 문제에 직면한다.

④ 딜레마 해소 (또는 난제 해결) 전략
 
- (B)의 **사적 검열** 비판은 '국가'의 (소극적)의무와 '플랫폼'의 (적극적)의무를 혼동한 범주 오류임을 논증한다. 
- (A)의 '연루'는 타인의 예측 가능한 해악에 인과적으로 기여하고도 이를 방치할 때 발생하는 명백한 도덕적 실패이다 (Kutz, 2000). 
- 따라서 (A)의 도덕적 실패(연류)가 (B)의 사적 검열 비판보다 더 중대하고 근본적인 문제이다. 플랫폼은 연루를 피하기 위한 적극적 중재 의무를 지닌다. 

## 2. 논증구조

### 기본구조(연역논증)

- **논제:** 대규모 알고리즘 기반 쇼셜 미디어 기업은 사용자가 게시하는 '부당하게 해롭거나 위험한 발언'을 적극적이고 선제적으로 중재해야 할 도덕적 의무를 지닌다. 
  - **전제1:** 플랫폼은 최소한의 비용으로 명백한 위험을 방지할 수 있으므로, '구조의 의무(duty of rescue)'를 지닌다. 
    - 근거 1. 모든 도덕적 행위자는 자신에게 큰 희생이 따르지 않는 한, 타인의 중대한 위험(예: 물에 빠진 아이)을 방지해야 할 일반적 의무를 지난다.(Singer, 1972)
	- 근거 2. 플랫폼은 AI 기술 등을 통해 혐오 발언, 자해 조장 콘텐츠 등 '명백한 위험'을 인지할 수 있으며, 이를 제거하는 것은 '큰 희생'이 아니다. 
  - **전제2:** 플랫폼은 단순 방관자가 아니라 자사 시스템을 통해 해악에 '연루(complicit)'되므로, 이를 적극적으로 회피할 더 강력한 의무를 지닌다.
    - 근거 1. ('연루'의 정의) 타인의 부당한 행위에 인과적으로 기여하고도(Contribution) 그 해악을 방지할 '합리적 조치'를 취하지 않을 때 도덕적 연루가 성립한다 (Howard, 2024).
    - 근거 2. 혐오 발언이 알고리즘을 통해 빠르게 확산되는 것이 '예측 가능'한 상황에서, 이미 해악이 발생한 뒤에 이뤄지는 '신고 후 삭제' 라는 소극적 조치는 이 연루를 피하기에 명백히 불충분하다.
  - **전제3:** 플랫폼은 단순 호스팅(중립적 공간 제공)을 넘어 '알고리즘 증폭'을 통해 해악에 결정적인 인과적 기여를 하므로, 이를 금지할 가장 엄격한 의무가 있다. 
      - 이익 극대화를 위해 부당한 발언을 알고리즘으로 '증폭(amplification)'시켜 더 많은 사람에게 노출하는 것은, 그 해악을 극대화한다는 점에서 단순 연루를 넘어선 적극적 기여이다 (Howard, 2024).
- **결론:** 따라서 플랫폼은 전제1의 '구조의 의무'를 지닌 뿐만 아니라, 전제2의 '연루'와 전제3의 '적극적 증폭'이라는 더 직접적인 책임을 지므로, 선제적인 중재에 나서야 한다.   

### 예상반론과 재반박

- **예상반론:** 전제 2는 '물리적 공간(아파트/주차장)'과 '디지털 플랫폼'을 '연루' 개념으로 동일시하는 오류를 범한다. 플랫폼의 데이터 규모와 확산 속도는 물리적 공간과 비견할 수 없이 방대하여(Keller, 2020), 해악을 '예측'하는 것이 사실상 불가능하다. 따라서 플랫폼에게 '합리적 조치'란 '신고 및 삭제'가 최대치이며, 그 이상(적극적 감시)을 요구하는 것은 '잘못된 유추'에 기반한 부당한 요구이다.
  - 논리적 취약점 지적: 전제2에는 '규모'와 '속성'이 본질적으로 다른 '물리적 공간'과 '디지털 플랫폼'을 통일선상에서 비교했다는 한계가 있다. 

- **재반박:** '예측 불가능' 주장은 '기술적 면죄부'에 불과하다. 플랫폼은 이미 상업적 이익을 위해 사용자의 행동을 (AI로) 정밀하게 '예측'하고 있다. 이 막대한 예측 기술을 해악 방지에 사용하는 것은 '불가능'한 것이 아니라 비용이 드는 것일 뿐이다. '합리적 조치'의 기준은 기술력에 비례해야 한다.

## 참고문헌

- Howard, J., (2024) “The Ethics of Social Media: Why Content Moderation is a Moral Duty”, Journal of Practical Ethics 11(2).

- Keller, D. (2020). "Who Do You Sue? State and Platform Hybrid Power". Harvard Journal of Law & Technology, 34.

- Singer, P., (1972) “Famine, Affluence, and Morality”, Philosophy & Public Affairs 1(3).