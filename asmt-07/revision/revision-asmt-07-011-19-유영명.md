---
title: (개선) 과제-07 개인별 논증 구조 작성하기 011-19 유영명
layout: home
nav_order: 99
parent: 011-19 유영명 (과제-07)
permalink: /asmt-07/011-19/revision
---

# (개선) 과제-07 개인별 논증 구조 작성하기 011-19 유영명 

## 개선 사항 메모

먼저, 전제3가 논제 자체를 반복하는 것 같다는 피드백을 받아서 누구의 어떤이 아닌 콘텐츠 개입 자체의 필요성을 강조하는 문구로 오해를 해소했다. 더불어, 전제1에서 사업자의 무책임이 혐오의 확산을 증폭한다는 비약이 있어 확산을 대중에게 노출시킨다는 책임으로 문구를 수정하였다. 전제2에서는 사회적 소수 집단에 대한 혐오표현이 정확히 논문에서 어떤 맥락으로 사회적 피해를 끼친다고 설명되는지 문장을 구체성을 강화했다. 또한, 논리의 인과 구조를 보충해야 한다는 피드백에 따라, 논지 설명을 조금 더 자세히 풀어나가며 설득력을 높였다. 
결론 문장에서는 구체적인 규제 방식의 예시가 있으면 좋을 것 같다는 피드백에 따라, 지속적인 모니터링과 플랫폼 내 규제라는 방안을 제시했다. 
재반론에서 등장하는 자극적인 콘텐츠라는 단어가 혐오표현 콘텐츠라는 범주를 흩뜨린다는 피드백에 따라, 해당 단어 대신 내용이라는 단어로 대체하였다. 이는 혐오표현 콘텐츠가 자극적인 내용을 담고 있어 플랫폼 구조 속 확산에 유리하다는 점을 설명하고자 한 것이다.


## 제목: 온라인 플랫폼 내의 혐오표현에 대한 사업자의 책임과 규제 필요성 

## 1. 쟁점과 딜레마

| 구분 | 내용 |
|:---|:---|
| 주제(Topic) | 온라인 플랫폼에서 확산되는 혐오 콘텐츠에 대한 사업자의 책임 |
| 도전하려는 쟁점 | 온라인 플랫폼 내 혐오표현 콘텐츠에 대해 플랫폼 사업자는 이를 규제해야 할 책임이 있는가? |
| 딜레마/난제 | 자유에 맡기면 혐오표현과 자극성 심화, 인위적으로 개입하면 표현의 자유 위협 |
| 딜레마/난제 해소/해결 방법 | 혐오표현의 피해가 더 심각하므로 콘텐츠 내용에 대한 책임이 있는 사업자의 규제와 개입이 필요하다는 논증 |

① 주제(Topic): 온라인 플랫폼에서 확산되는 혐오표현 콘텐츠에 대한 규제 필요성 

② 도전하는 학술적 쟁점:혐오표현을 억제해야 하는 사회적 필요에 대해 플랫폼 사업자는 혐오표현 콘텐츠 규제할 책임이 있는가?

- **“혐오표현을 억제해야 하는 사회적 필요”와 “표현의 자유 보장이라는 헌법적 가치” 사이 어느 것을 우선시해야 하는가?**
- **플랫폼에 업로드된 혐오표현 콘텐츠는 그저 자유로운 콘텐츠 업로더의 책임인가, 플랫폼 사업자의 책임인가?** 
- **플랫폼 사업자의 규제와 개입이 불가피하다면, 어떤 방식으로 규제해야 하는가?**

③ 유발되는 딜레마 또는 난제

- 딜레마 구조
  - **(A)** 사용자들의 자유표현에 온전히 맡기면 혐오표현과 자극성 심화되어 심각한 사회적 피해을 초래할 것이다.
  - **(B)** 그러나 사업자가 개입한다면 표현의 자유에 대한 억압으로 인해 기본권 침해, 검열, 윤리적 논란 등의 문제가 발생할 위험이 있다.

④ 딜레마 해소 (또는 난제 해결) 전략

- 플랫폼 사업자는 단순 중개자 수준을 넘어 콘텐츠 유통 및 확산 구조에 영향을 미치므로, 콘텐츠 규제와 개입의 책임이 있는 존재로 봐야 한다. (최우정, 2020)
- 혐오표현, 허위정보, 폭력 선동을 그대로 두는 것은 ‘**무책임한 자유주의**’이며, 오히려 자유 자체를 훼손한다. (Howard, 2024)
- 따라서 표현의 자유는 타인의 존엄과 안전이 보장되는 조건 하에서만 실현가능한 권리로, 혐오표현 콘텐츠에 대한 사업자의 개입은 표현의 자유를 침해하는 것이 아니라 자유를 보호하기 위한 ‘**책임 있는 규제**’이다.

## 2. 논증구조

### 기본구조

- **논제:** 온라인 플랫폼 내 혐오표현 콘텐츠에 대해 사업자의 강력한 규제와 개입이 반드시 필요하다.
  - **전제1:** 플랫폼 사업자는 단순 중개자 수준을 넘어 콘텐츠 유통 및 확산 구조에 영향을 미치므로, 책임을 부여받아야 하는 존재로 봐야 한다. (최우정 2020, p.135-140)
    - 플랫폼은 그저 온라인 사용자들의 콘텐츠 확산을 매개하는 중립적 통로가 아닌, 혐오표현의 확산을 조장, 억제할 수 있는 구조적 권력자이다. 플랫폼 사업자는 콘텐츠의 방향성을 실질적으로 조정하는 구조적 행위자이다. (최우정, 2020, p.136-138)
	- 결과적으로, 구조적 영향력, 실질적인 능력이 있는 플랫폼 사업자의 무개입과 방조는 혐오표현을 그대로 대중에게 노출한다는 사회적, 구조적, 윤리적 책임으로 귀결된다. (최우정, 2020, p.139-142)
  - **전제2:** 혐오표현을 온라인 플랫폼에 그대로 두는 것은 '무책임한 자유주의'이며, 이는 타인의 존엄과 안전을 위협함으로써 오히려 자유의 토대를 붕괴시켜 표현의 자유를 위협한다. (Howard, 2024, p.33-36)
    - 사회적 약자나 소수자 집단이 자신들에 대한 모욕과 조롱 등 혐오표현 콘텐츠에 지속적으로 노출될 때, 이들은 피해자로서 위축되고 사회적 차별과 편견이 강화된다. 소수와 주변부의 공론장 참여권이 사실상 차단되고 공론장은 점점 더 다수의 것으로 왜곡되어서, 이들의 실질적 표현의 자유가 약화된다. (Howard, 2024, p.37-39)
    - 따라서, 표현의 자유는 타인의 존엄과 안전이 보장되는 조건 하에서만 실현 가능한 권리이며, 플랫폼의 책임 없는 방임은 자유의 본질을 스스로 훼손하는 결과를 초래한다. (Howard, 2024, p.40-42)
  - **전제3:** 개입이 없거나 늦었던 혐오표현 콘텐츠가 사회적으로 큰 피해와 위험, 불쾌감을 초래한 사건이 많아서 이에 대한 규제가 필요하다.
      - 온라인 영상 플랫폼에서 자극적인 소재로 조회수와 수익을 끌어들이기 위해 범죄와 혐오로 가득한 콘텐츠들이 생산되고 있다. 특히, 유튜브 영상을 통해 서로 비방하던 경쟁 관계의 유튜버를 생방송 라이브에서 살해한 사건은 큰 영향을 끼쳤다. 해당 영상은 한국 방심위의 요청 하에, 업로드된지 10시간이 지난 후에야 삭제 조치가 이뤄졌다. 플랫폼 사업자의 적극적인 개입이 없던 10시간동안 폭력적이고 불쾌감을 자아낸 영상은 모든 대중들에게 아무런 조치 없이 그대로 공개되고 있었던 것이다. (이정현, 2024)
      - 온라인 플랫폼에서 같은 성향을 가진 사람들은 더욱 극단으로 치닫는 현상을 집단극화라고 한다. 특정 대상을 향한 혐오표현 콘텐츠 또한 온라인 상에서 확산되며 극단적인 행동을 만들어내기도 한다. 2015년 경 독일에서 진행한 연구에서 지역별 반난민 게시물과 난민 대상 폭력 범죄의 상관관계를 증명하여 플랫폼 속 혐오성향이 실질적인 사회, 물리적 피해로 이어졌다는 것이 정당화되었다. 더불어, 페이스북과 인터넷의 장애가 잇을 때 유의미하게 해당 범죄가 크게 감소하기도 했다. (Müller & Schwarz, 2021)
- **결론:** 따라서, 사업자의 지속적인 콘텐츠 모니터링과 플랫폼 내 규제와 같은 강력한 개입으로 온라인 플랫폼 내 혐오표현 콘텐츠를 반드시 규제해야 한다.

### 예상반론과 재반박

- **예상반론(연역적 논증의 타당성 공격):** **전제1**의 내용은 콘텐츠 내용과는 상관없는 중립적인 입장의 온라인 플랫폼 사업자에게 과도하게 책임을 전가한다.
  - 논리적 취약점 지적: 플랫폼이 콘텐츠 유통 구조에 영향을 미치고 그 사업자가 이러한 혐오표현 콘텐츠 확산을 저지할 능력과 영향력이 있다고 하나, 그것이 곧바로 온라인 플랫폼 사업자에게 '책임'을 귀속시키지 못한다. 즉, 통제 능력과 행위 책임 사이의 인과적 비약이 존재하는 것이다. 

- **재반박:** 그러나, 온라인 플랫폼 사업자는 혐오표현과 같은 자극적인 내용이 선호되고 확산되는 플랫폼 위험한 설계 구조에서 경제적 이익을 얻는다. 즉, 사업자가 플랫폼 구조를 설계하는 단계에서 혐오표현 콘텐츠라는 예견 가능한 위험을 그대로 방치하고 수익을 우선시하는 것은, 소극적 방임이자 도덕적 공모로 평가할 수 있다.

## 참고문헌

- 최우정. (2020). 온라인 동영상 서비스를 통해 확산되는 혐오표현과 플랫폼 서비스 사업자의 책임. 법학연구, 62, 125–150.
- 김형지, 김유석, & 김용희. (2021). 온라인 동영상 서비스의 혐오표현 콘텐츠 이용 경험과 규제 인식이 이용과 지속 이용 의도에 미치는 영향. 서비스경영학회지, 22(1), 231–249.
- Howard, J. (2024). The Ethics of Social Media: Why Content Moderation is a Moral Duty. Journal of Practical Ethics, 11(2).
- Müller, K., & Schwarz, C. (2021). Fanning the Flames of Hate: Social Media and Hate Crime. Journal of the European Economic Association, 19(4), 2131–2167.
- 이정현. (2024년5월16일). 구글, 방심위에 "유튜브 불법 콘텐츠 최대한 신속히 삭제" 약속. *연합뉴스*. https://www.yna.co.kr/view/AKR20240516088200017
    