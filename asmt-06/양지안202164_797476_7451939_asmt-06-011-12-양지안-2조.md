---
title: (011-12 양지안) 문헌1
layout: home
nav_order: 12
parent: 과제-06 (2조) 개조식 요약문
permalink: /asmt-06/002/011-12
---

# 과제-06 (조별) 개조식 요약문 작성 011-12 양지안

## 소속 조/선정 주제

- 소속 조: 2조
- 선정된 주제: 뉴스 및 소셜미디어 플랫폼은 사용자 콘텐츠에 대한 책임을 지니는가? 
- 주제에 대한 설명(1문장): 뉴스 및 소셜미디어 등 사용자 콘텐츠 문제에 대하여 해당 콘텐츠를 유통하는 플랫폼이 문제의 책임에서 자유로울 수 있는가에 대해 다루고자 한다.
- 본인이 해당 문헌을 담당하게 된 배경에 대한 간략한 설명(문헌별 1문장): 
  - 문헌1: 해당 문헌은 플랫폼의 알고리즘적 편집 행위를 논리적으로 분석하고 있어, 메타 관련 미국 교육구 집단 소송 사례에 적용함으로써 플랫폼이 행위자로서 책임을 져야 하는 이유를 설득력 있게 논증할 수 있다.

## 1. 'Automated Trouble: The Role of Algorithmic Selection in Harms on Social Media Platforms' – Saurwein, F. & Spencer-Smith, C. (2021)

- **서지정보**: Saurwein, F. & Spencer-Smith, C. (2021). *Automated Trouble: The Role of Algorithmic Selection in Harms on Social Media Platforms*. Media \& Communication, Vol 9, Issue 4, pp. 222-233.
- **쟁점**: 소셜미디어 플랫폼은 단지 사용자가 올린 콘텐츠를 중개하는 중립적 공간 제공자인가, 아니면 알고리즘을 통해 유해한 콘텐츠를 선별, 증폭함으로써 발생한 사회적 피해에 대해 책임을 져야 하는 ‘편집적 행위자’인가? 
- **딜레마**: 플랫폼이 중립적 기술 인프라라면, 왜 알고리즘 설계와 운영이 사회적 해악에 영향을 미치는가? /
반대로, 플랫폼이 적극적 편집 행위자라면, 사용자 자율성과 표현의 자유는 어떻게 보장될 수 있는가?
- **주장**: 소셜미디어의 알고리즘적 선택(algorithmic selection)은 단순한 중개 행위가 아니라, 콘텐츠의 노출 범위와 주목도를 조정하는 ‘편집적 개입(editorial intervention)’이므로 플랫폼은 알고리즘 설계와 운영에서 비롯된 사회적 결과에 대해 일정한 책임을 져야한다.
- **논증 방식**: Saurwein과 Spencer-Smith(2021)는 소셜미디어 플랫폼이 단순히 사용자가 생산한 콘텐츠를 전달하는 중립적 기술 인프라가 아니라, 알고리즘을 통해 콘텐츠의 노출과 확산을 적극적으로 조정하는 편집적 행위자(editorial actor)임을 논증한다. 저자들은 먼저 기존 플랫폼 책임 담론이 “플랫폼은 단지 중개자(intermediary)에 불과하다”는 전제 위에서 형성되어 왔음을 지적하며, 이 전제가 실제 알고리즘의 작동 방식과 사회적 영향력을 설명하지 못한다는 점을 논리적으로 반박한다. 즉, 플랫폼은 콘텐츠의 흐름에 개입하지 않는다는 기존의 ‘중립성 전제’가 현실적 사실과 맞지 않는다는 것이다.

   이에 저자들은 새로운 대전제를 제시한다. 곧, “알고리즘적 선택(algorithmic selection)은 기술적 자동화가 아니라 편집적 행위(editorial act)”라는 것이다. 플랫폼의 알고리즘은 사용자 참여를 극대화하기 위해 감정적으로 자극적이거나 극단적인 콘텐츠를 우선 노출하며, 이로 인해 허위정보나 혐오 발언이 비정상적으로 확산된다. 이러한 현상은 플랫폼이 단순히 정보 전달을 중개하는 것이 아니라, ‘무엇을 보이게 할 것인가’를 스스로 결정하는 편집적 판단 주체로 기능하고 있음을 보여준다.

   이 논증은 연역적 구조를 따른다. 먼저 기존 전제인 “플랫폼은 단지 중개자다”가 경험적 사실과 맞지 않음이 입증된다. 이어 새로운 대전제인 “알고리즘적 선택은 편집적 행위다”가 설정되고, 이를 바탕으로 “편집적 행위를 수행하는 주체는 그 행위의 사회적 결과에 대해 책임을 져야 한다”는 규범적 원칙을 적용한다. 플랫폼이 공중 담론 형성에 실질적으로 개입하고, 그 행위가 허위정보와 혐오 발언 등 사회적 해악을 초래한다는 사실이 소전제로 결합되면서, “따라서 플랫폼은 그 편집적 결정으로 발생한 결과에 대해 책임을 져야 한다”는 결론이 자연스럽게 도출된다. 즉, 기존의 중립성 전제를 깨고 알고리즘을 통한 편집적 개입을 새로운 규범적 전제로 설정하며 여기에 유비 추론과 규범적 원칙을 결합함으로써 플랫폼의 편집적 책임(editorial accountability)이 연역적으로 정당화되는 구조이다. 이 과정에서 경험적 사례는 논증의 실증적 토대를 제공하고, 유비 추론은 규범적 책임을 강화하며, 연역적 추론은 결론 도출의 논리적 흐름을 명확하게 연결하는 역할을 한다.

